# Nomencl√°tor

**Nomencl√°tor** es una red neuronal LSTM que genera nombres de localidades espa√±olas y corre en el navegador sin necesidad de instalar ning√∫n tipo de software ni GPU. En este documento cuento casi paso a paso como duplicar el proceso de descarga de datos, entrenamiento y uso, aunque se puede saltar directamente al tercer paso.

# TL;DR

Si quer√©is probar el generador sin instalar nada, ni ver el c√≥digo ni saber c√≥mo est√° hecho, id directamente a  [https://neuronasmuertas.com/nomenclator/](https://neuronasmuertas.com/nomenclator/).

# Datos

El primer paso es encontrar un conjunto de datos lo suficientemente amplio para que la red "entienda" la estructura de los nombres de las poblaciones. Afortunadamente, he localizado una tabla de la Agencia Tributaria con todas las poblaciones de Espa√±a a septiembre de 2019, en otro caso tocaba scrapear datos de diferentes p√°ginas.

[Tabla de poblaciones y localidades](https://www.agenciatributaria.es/AEAT.internet/Inicio/Ayuda/Tablas_auxiliares_de_domicilios__provincias__municipios____/Tabla_de_Poblaciones_y_Localidades/Tabla_de_Poblaciones_y_Localidades.shtml)

Es un fichero de texto plano (`poblaciones_original_2019.txt`) de unas 60.000 entradas con este formato

![Tabla de poblaciones](https://user-images.githubusercontent.com/1846199/89101878-63f24180-d404-11ea-866e-4c1b11c6fe7d.png)

as√≠ que hay que limpiarlo un poco: dejar √∫nicamente el nombre de las poblaciones (columnas 16 a 66), quitar los espacios, eliminar duplicados y desordenar el fichero. El script `limpia_poblaciones.sh` hace esas cuatro operaciones exactamente en ese orden...

```bash
#!/bin/bash

LC_CTYPE=C && LANG=C && cut -c16-66 ./poblaciones_original_2019.txt | \
sed -e 's/[[:space:]]*$//' | \
sort -u | \
sort -R > ./poblaciones.txt
```

... y genera un fichero nuevo (`poblaciones.txt`) con unas 40.000 localidades (¬°Hay casi 20.000 poblaciones con el nombre repetido!)

Este n√∫mero de entradas es m√°s que suficiente para entrenar la red. A partir de 10.000 ejemplos ya se obtienen resultados dignos para este tipo de generaci√≥n. Si en vez de nombres quisi√©ramos generar frases o textos medio coherentes, necesitar√≠amos muuuuchos m√°s datos.

üëâüèº El fichero original, el fichero limpio y el script para limpiar el fichero se encuentra en la carpeta `datos`.

# Entrenamiento

Si quer√©is usar la red sin entrenarla, pod√©is saltar directamente a la secci√≥n "**Generaci√≥n**".

üëâüèº Todos los ficheros de esta secci√≥n se encuentran en la carpeta `entrenamiento`.

Para entrenar la red neuronal uso el script de Python [training-charRNN](https://github.com/ml5js/training-charRNN). Necesita Python y TensorFlow 1.15. Lamentablemente, instal√© TensorFlow hace casi un a√±o y no me acuerdo exactamente de c√≥mo lo hice, salvo que fue creando un entorno con anaconda. 

Si us√°is la versi√≥n de `train.py` que he incluido en el repositorio, no hay que tocar nada. Si us√°is la original, hay que modificar la l√≠nea 98 para especificar la codificaci√≥n del fichero de las poblaciones (latin-1), o se atascar√° con las tildes.

```python
data_loader = TextLoader(args.data_path, args.batch_size, args.seq_length, encoding='latin-1')
```

El entrenamiento empieza al ejecutar el script `run.sh`. 

```bash
#!/bin/bash

python train.py --data_path=../datos/poblaciones.txt \
--rnn_size 256 \
--num_layers 2 \
--seq_length 64 \
--batch_size 32 \
--num_epochs 20 \
--output_keep_prob 0.75 \
--model lstm \
--save_checkpoints ./checkpoints \
--save_model ./models \
--print_every 10

#--model: rnn, gru, lstm, nas

rm -r ../generacion/models/poblaciones
cp -r ./models/poblaciones ../generacion/models/poblaciones
```

Es casi igual al script original, pero he afinado un poco los hiperpar√°metros (b√°sicamente, 256 neuronas, memorizaci√≥n de secuencias de 64 caracteres, un batch m√°s peque√±o y menos epochs). Cuando lo arranqu√©is dar√° un mont√≥n de errores, es normal. Al cabo de un rato empezar√° el entrenamiento propiamente dicho y ver√©is algo parecido a esto:

![El festival del error.](https://user-images.githubusercontent.com/1846199/89101859-3f966500-d404-11ea-9422-fe10733b67c1.png)



Una vez que termina de ejecutarse (una hora, m√°s o menos, en mi ordenador sin GPU), el script copiar√° los resultados en la carpeta `generacion/models`.

# Generaci√≥n

üëâüèº Todos los ficheros de esta secci√≥n se encuentran en la carpeta `generacion`.

La chicha de la generaci√≥n est√° en el fichero `sketch.js`.  B√°sicamente, carga los ficheros que hay en la carpeta `generacion/models` y llama a la red neuronal cada vez que se pulsa el bot√≥n. Adem√°s del bot√≥n, hay un slider para ajustar la temperatura de los resultados, es decir, lo conservadores u osados que van a ser. Si se selecciona un valor peque√±o, la red neuronal se embucla y saca siempre los mismos resultados. Si se selecciona un valor cercano a 1, los resultados son m√°s variados, pero a veces obtiene combinaciones de letras no v√°lidas, no cierra los par√©ntesis, etc.

üå°Temperatura de 0.15

```
CASTRO DE LA CABALLERA
CASTRO DE MONTE (O)
CASTRO DE ABAIXO
CASTRO DE ARRIBA
CASTRO DE ABAIXO
CASTRO DE ARRIBA
CASTRO DE ABAIXO
CASTRO DE ARRIBA
PALACIOS DE LA SIERRA
CASTRO DE ARRIBA
CASTRO DE ARRIBA
VILAR DE CASTRO
CASTRO DE CASTRO
```

üå°Temperatura de 1.00

```
CASTEELONS
TABLAVIEJA DE TORMES
PREUTA
SACUNTE-HUERTO
HUERCADOR
CANDAS
USLEDO DE ARRIBA
PLASENDE
LAROTE
SONDOS
PORTOFRIO (O)
BLECIO
MONFORTALES
```

Una vez que la red neuronal devuelve los resultados, eliminamos el primero y el √∫ltimo ‚Äìsuelen estar cortados‚Äì y presentamos el resto.

Si quer√©is ejecutar el c√≥digo en local, basta con levantar un servidor web en la carpeta `generacion`. Para ello hay que abrir una ventana de terminal, ir a la carpeta y teclear alguno de estos comandos (naturalmente, tienes que tener Python o PHP instalado en tu equipo)

**Python 2.x**

```python
python -m SimpleHTTPServer 8000
```

**Python 3.x**

```python
python -m http.server 8000 --bind 127.0.0.1
```

**PHP**

```php
php -S localhost:8000
```
